{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ptdat/Desktop/venv/lib/python3.12/site-packages/peft/mapping_func.py:96: UserWarning: lora with eva initialization used with low_cpu_mem_usage=False. Setting low_cpu_mem_usage=True can improve the maximum batch size possible for eva initialization.\n",
            "  warnings.warn(\n",
            "[\u001b[32;20mTrainer\u001b[0m][\u001b[34;20mINFO\u001b[0m][\u001b[35;20m05-06 22:39:27\u001b[0m]: \n",
            "    Model: ViSoBERT\n",
            "    Training size: 28243\n",
            "    Dev size: 4688\n",
            "    Ablate: image\n",
            "    Target speech level: 1\n",
            "    Label merge: None\n",
            "    Patience: 2\n",
            "    Batch size: 1\n",
            "    Learning rate: 0.0001\n",
            "    Gradient norm clip: 1.0\n",
            "    Weight decay: 0.0\n",
            "    Gradient accumulation: 64\n",
            "    Class weight: None\n",
            "    Device: cuda:0\n",
            "    \n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                                           Param #\n",
            "=========================================================================================================\n",
            "DistributedDataParallel                                                          --\n",
            "├─PeftModel: 1-1                                                                 --\n",
            "│    └─LoraModel: 2-1                                                            --\n",
            "│    │    └─ViSoBERT: 3-1                                                        201,623,043\n",
            "=========================================================================================================\n",
            "Total params: 201,623,043\n",
            "Trainable params: 7,672,323\n",
            "Non-trainable params: 193,950,720\n",
            "=========================================================================================================\n",
            "Training:   0%|                                    | 0/28243 [00:00<?, ?batch/s][rank0]:[W605 22:39:42.999412652 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Training:  14%|█▉            | 3867/28243 [07:01<55:54,  7.27batch/s, loss=1.27]"
          ]
        }
      ],
      "source": [
        "!python3 train.py \\\n",
        "    --model=ViSoBERT \\\n",
        "    --ablate=image \\\n",
        "    --target-cmt-lvl=1 \\\n",
        "    --label-merge=none \\\n",
        "    --early-stop-patience=2 \\\n",
        "    --monitor=f1-score \\\n",
        "    --batch-size=1 \\\n",
        "    --eval-batch-size=1 \\\n",
        "    --learning-rate=1e-4 \\\n",
        "    --lora-rank=16 \\\n",
        "    --grad-clip=1 \\\n",
        "    --weight-decay=0 \\\n",
        "    --grad-accum=64 \\\n",
        "    --cls-weight=no \\\n",
        "    --use-aug=yes \\\n",
        "    --instruct=no \\\n",
        "    --resume=no \\\n",
        "    --dist=yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\u001b[32;20mEvaluator\u001b[0m][\u001b[34;20mINFO\u001b[0m][\u001b[35;20m05-06 22:37:01\u001b[0m]: Evaluation score:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean     0.8819    0.9421    0.9110      3488\n",
            "   Offensive     0.6972    0.5861    0.6368       947\n",
            "        Hate     0.6364    0.1750    0.2745       120\n",
            "\n",
            "    accuracy                         0.8479      4555\n",
            "   macro avg     0.7385    0.5677    0.6074      4555\n",
            "weighted avg     0.8370    0.8479    0.8372      4555\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 evaluate.py \\\n",
        "    --model=ViSoBERT \\\n",
        "    --ablate=image \\\n",
        "    --target-cmt-lvl=1 \\\n",
        "    --label-merge=none \\\n",
        "    --batch-size=2 \\\n",
        "    --instruct=no \\\n",
        "    --save-preds=no \\\n",
        "    --dist=yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-11 23:19:38 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
            "[\u001b[32;20mAugmentation\u001b[0m][\u001b[34;20mINFO\u001b[0m][\u001b[35;20m11-04 23:20:32\u001b[0m]: \n",
            "AUGMENTED LABELS:\n",
            "Level 1: Hate: 5744, Offensive: 5435, Clean: 3114\n",
            "Level 2: Hate: 2352, Offensive: 2179, Clean: 1270\n",
            "Overall: Hate: 8096, Offensive: 7614, Clean: 4384\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 augment.py \\\n",
        "    --synonym-rate=0.1 \\    \n",
        "    --rm-word-prob=0.02 \\\n",
        "    --out-dir=./ViContextHSD/aug"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
