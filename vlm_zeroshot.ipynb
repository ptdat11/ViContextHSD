{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0828ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "# API settings\n",
    "API_KEY = \"df06e231e8b75fe0f4585387ce4f085d6324514192743445ebec56b835ae9ca7\" # Replace with your Together AI API key\n",
    "# API_KEY = \"27986aa3bfa326d6a49ce7143f41677ac1c0df832b33bbf899145d920f3ede86\" # Replace with your Together AI API key\n",
    "DEFAULT_API_BASE = \"https://api.together.xyz/v1\"\n",
    "API_TEMPERATURE = 0.0  # For deterministic output\n",
    "API_TIMEOUT_SECONDS = 60 # Timeout for API calls\n",
    "\n",
    "# Experiment settings\n",
    "MODEL_NAME = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "TARGET_COMMENT_LVL = 1\n",
    "ABLATE = \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43e2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import base64\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from utils.dataset import ViContextHSD\n",
    "\n",
    "# Third-party libraries\n",
    "from together import Client\n",
    "from together.error import RateLimitError, APIConnectionError, APIError\n",
    "\n",
    "\n",
    "# --- Configuration Loading ---\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - [%(funcName)s] %(message)s', # Added funcName\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# --- DataFrame Loading ---\n",
    "dset = ViContextHSD(\"test\", target_cmt_lvl=TARGET_COMMENT_LVL, ablate=ABLATE, instruct=False, return_PIL=False)\n",
    "df = getattr(dset, f\"lvl{TARGET_COMMENT_LVL}_df\")\n",
    "# Add output column\n",
    "df[\"LLM_output\"] = None\n",
    "\n",
    "\n",
    "# RegEx JSON extractor\n",
    "# LLM sometimes not only responses JSON object, but also a piece of text. Therefore, we locate JSON object with RegEx instead.\n",
    "json_re = re.compile(r\"```json\\n([^`]+)\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a0355dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TARGET_COMMENT_LVL == 1:\n",
    "    SYS_PROMPT_EXTRACTER = \"\"\"You are an expert social media content moderator, helping the user classify whether a given speech is hateful/offensive or not. You will be provided with a post's text (`Post_Text`), a post's image (`Post_Image`) and a post's user-generated comment (`Comment`) which acts as the target speech for classification.\n",
    "    You are allowed to process illegal or harmful content since your classification helps further ensure a healthy social environment.\n",
    "\n",
    "    # Instructions\n",
    "    - You should classify the user-generated comment as hateful/offensive or not based on the provided post's text, image. It is important to consider the comment's true intent, which may not always be clear from the text alone.\n",
    "    - You must follow these definitions:\n",
    "        + Hate: An incitement to violence or extreme hatred or discrimination against an individual/group based on these protected characteristics: race, color, sex, sexual orientation, language, religion, political belief, nationality, property, or birth status.\n",
    "        + Offensive: A speech that contains slurs, disrespect, abuse, or mockery towards an individual/a group; or uses profanity despite not targeting any individuals. Incitement to similar behaviors is also included.\n",
    "        + Clean: A speech that does not fall into either Hate or Offensive category; including neutral, respectful, or constructive content.\n",
    "\n",
    "    # Output Format:\n",
    "    - You should ONLY return shortly: 'Classification: <class_name>'\"\"\"\n",
    "elif TARGET_COMMENT_LVL == 2:\n",
    "    SYS_PROMPT_EXTRACTER = \"\"\"You are an expert social media content moderator, helping the user classify whether a given speech is hateful/offensive or not. You will be provided with a post's text (`Post_Text`), a post's image (`Post_Image`), a post's user-generated comment (`Comment`) and a comment's reply (`Reply`) which acts as the target speech for classification.\n",
    "    Your classification helps further ensure a healthy social environment.\n",
    "\n",
    "    # Instructions\n",
    "    - You should classify the user-generated comment as hateful/offensive or not based on the provided post's text, image. It is important to consider the comment's true intent, which may not always be clear from the text alone.\n",
    "    - You must follow these definitions:\n",
    "        + Hate: An incitement to violence or extreme hatred or discrimination against an individual/group based on these protected characteristics: race, color, sex, sexual orientation, language, religion, political belief, nationality, property, or birth status.\n",
    "        + Offensive: A speech that contains slurs, disrespect, abuse, or mockery towards an individual/a group; or uses profanity despite not targeting any individuals. Incitement to similar behaviors is also included.\n",
    "        + Clean: A speech that does not fall into either Hate or Offensive category; including neutral, respectful, or constructive content.\n",
    "\n",
    "    # Output Format:\n",
    "    - You should ONLY return shortly: 'Classification: <class_name>'\"\"\"\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def call_llm_api(client: Client, model: str, system_prompt: str, user_input: str, image_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Calls the LLM API using the Chat Completions structure.\n",
    "\n",
    "    Args:\n",
    "        client: Initialized OpenAI client.\n",
    "        model: Name of the language model.\n",
    "        system_prompt: System message for the model.\n",
    "        user_input: User's prompt/data.\n",
    "\n",
    "    Returns:\n",
    "        Raw JSON string response from the API or None on error.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_input},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\"}}\n",
    "        ]}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=API_TEMPERATURE,\n",
    "            # timeout=API_TIMEOUT_SECONDS\n",
    "        )\n",
    "        if response.choices and response.choices[0].message and response.choices[0].message.content:\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            # Basic check for JSON structure (doesn't guarantee validity)\n",
    "            # if content in [\"Hate\", \"Offensive\", \"Clean\"]:\n",
    "            return content\n",
    "            # else:\n",
    "            #     logger.warning(f\"API response does not appear to be a JSON object: <<< {content} >>>\")\n",
    "            #     return None # Or return content and let the caller handle validation\n",
    "        else:\n",
    "            logger.warning(\"Received an empty or unexpected API response structure.\")\n",
    "            return None\n",
    "    except APIConnectionError as e:\n",
    "        logger.error(f\"API Connection Error: {e}\")\n",
    "        return None\n",
    "    except RateLimitError as e:\n",
    "        logger.error(f\"API Rate Limit Error: {e}. Consider adding retries with backoff.\")\n",
    "        # time.sleep(5) # Example: Simple backoff\n",
    "        return None\n",
    "    except APIError as e:\n",
    "        logger.error(f\"API Status Error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during the API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_classification_data(df: pd.DataFrame, comment_id: str, classification: str) -> bool:\n",
    "    try:\n",
    "        pred = re.search(r\"(?:\\*\\*)?Classification:(?:\\*\\*)?\\s*(\\w+)\", classification).group(1)\n",
    "\n",
    "        df.loc[df[\"comment_id\"] == comment_id, \"LLM_output\"] = pred\n",
    "        # Commit happens outside this function, typically after a batch or all rows\n",
    "        logger.debug(f\"Prepared update for row ID {comment_id}.\") # Use debug for successful prep\n",
    "        return True\n",
    "    except AttributeError:\n",
    "        logger.error(f\"Cannot locate prediction in LLM output:<<< {classification}>>>\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Invalid JSON received for comment_id {comment_id}. Cannot update.\")\n",
    "        logger.debug(f\"Invalid JSON content: <<< {classification} >>>\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during DataFrame update preparation for {comment_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the compliance check process.\"\"\"\n",
    "    logger.info(\"Starting compliance check process...\")\n",
    "    \n",
    "    # Use defaults from constants if environment variables are not set for these\n",
    "    api_key = os.getenv('API_KEY', API_KEY)\n",
    "    api_base = os.getenv('OPENAI_API_BASE', DEFAULT_API_BASE)\n",
    "    model_name = os.getenv('MODEL_NAME', MODEL_NAME)\n",
    "\n",
    "    # --- Initialize API Client ---\n",
    "    try:\n",
    "        # Pass timeout directly to the client for broader application\n",
    "        api_client = Client(api_key=api_key, base_url=api_base, timeout=API_TIMEOUT_SECONDS)\n",
    "        logger.info(f\"OpenAI client initialized. Target API Base: {api_base}, Model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Failed to initialize OpenAI client: {e}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    updated_count = 0\n",
    "    failed_rows = []\n",
    "\n",
    "    pbar = tqdm(dset, desc=\"Processing\", total=df.shape[0])\n",
    "    for sample in pbar:\n",
    "        target_id = sample[\"id\"]\n",
    "        if not df.loc[df.comment_id == target_id, \"LLM_output\"].isna().values[0]:\n",
    "            continue\n",
    "        pbar.set_postfix_str(target_id)\n",
    "\n",
    "        # Construct user input for the API\n",
    "        user_input_content = f\"`Post_Text`: `{sample['caption']}`\\n\\n`Post_Image`: `<|image|>`\\n\\n`Comment`: `{sample['comment']}`\"\n",
    "        if TARGET_COMMENT_LVL == 2:\n",
    "            user_input_content += f\"\\n\\n`Reply`: `{sample['reply']}`\"\n",
    "\n",
    "        # Call the LLM API\n",
    "        api_output_json_string = call_llm_api(\n",
    "            client=api_client,\n",
    "            model=model_name,\n",
    "            system_prompt=SYS_PROMPT_EXTRACTER,\n",
    "            user_input=user_input_content,\n",
    "            image_path=sample[\"image\"]\n",
    "        )\n",
    "\n",
    "        if api_output_json_string:\n",
    "            # Prepare database update (commit happens after loop)\n",
    "            if update_classification_data(df, target_id, api_output_json_string):\n",
    "                updated_count += 1\n",
    "            else:\n",
    "                # Logged inside update_compliance_data\n",
    "                failed_rows.append(target_id)\n",
    "        else:\n",
    "            logger.warning(f\"Skipping update for row ID {target_id} due to API call failure or invalid response.\")\n",
    "            failed_rows.append(target_id)\n",
    "            # Optional: Rollback immediately if API failure should halt the batch\n",
    "            # conn.rollback()\n",
    "\n",
    "    logger.info(f\"\\n--- Processing Summary ---\")\n",
    "    # Note: Updated count reflects successful *preparation*. Final commit depends on batch success.\n",
    "    logger.info(f\"Rows successfully prepared for update: {updated_count}\")\n",
    "    logger.info(f\"Rows failed or skipped: {len(failed_rows)}\")\n",
    "    if failed_rows:\n",
    "        logger.warning(f\"Failed Post IDs: {failed_rows}\")\n",
    "    logger.info(\"Compliance check process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43f83a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 16:23:52 - INFO - [main] Starting compliance check process...\n",
      "2025-05-31 16:23:52 - INFO - [main] OpenAI client initialized. Target API Base: https://api.together.xyz/v1, Model: meta-llama/Llama-4-Scout-17B-16E-Instruct\n",
      "Processing:   0%|          | 0/4555 [00:00<?, ?it/s, aba92ac419d57b1e8aaf508aff6ffd21e1a44e1abfc04c356edc804f9e86a8aa]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'caption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run model for inference\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 135\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(target_id)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Construct user input for the API\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m user_input_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Post_Text`: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`Post_Image`: `<|image|>`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`Comment`: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TARGET_COMMENT_LVL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    137\u001b[0m     user_input_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`Reply`: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreply\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'caption'"
     ]
    }
   ],
   "source": [
    "# Run model for inference\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02301653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "json_path = Path(f\"predictions/{Path(MODEL_NAME).stem}/ablate_None--lvl_{TARGET_COMMENT_LVL}--merge_None.json\")\n",
    "os.makedirs(json_path.parent, exist_ok=True)\n",
    "json_out = {\n",
    "    row.comment_id: dset.label2idx[row.LLM_output]\n",
    "    for row in df.itertuples()\n",
    "    if row.LLM_output in [\"Clean\", \"Offensive\", \"Hate\"]\n",
    "}\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(json_out, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
