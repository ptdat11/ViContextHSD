import regex as re
import os
# from py_vncorenlp import VnCoreNLP
# import emoji
import unicodedata
import json

# cwd = os.getcwd()
# vncorenlp = VnCoreNLP(annotators=['wseg'], save_dir=os.environ['VNCORENLP'])
# os.chdir(cwd)

PHONE_RE = re.compile(r"\(?([0-9]{3})\)?([ .-]?)([0-9]{3})\2([0-9]{4})")
DUP_TRALLING_RE = re.compile(r"([\D\w])\1+\b")
SYLLABLE_RE = re.compile(r'(<[^<>]+>)|\b\w+\b|\X')
GROUPING_SEPARATOR_RE = re.compile(r"(?<=\d)[\.,](?=\d{3})")
VALUE_UNIT_RE = re.compile(r"(\d+)(\D+)")
PUNCTUATION_RE = re.compile(
    # "([" + re.escape("!\"#$%&'()*+,-./:;<=>?@[\\]^`{|}~") + "])"
    r'(<[^<>]+>)|([^\w\s])'
)
# EMOJI_RE = emoji.replace_emoji()

SPECIAL_WORD_SUBSTITUTION = {
    "@@": "confuseeyes",
    "‚ÑÖ": "%",
    r"\n": "<newline>",
    r"/": " fraction ",
    r":\)+": "smileface",
    r";\)+": "smileface",
    r":\*+": "kissingface",
    r"=\)+": "playfulsmileface",
    r"=\(+": "playfulsadface",
    r":\(+": "sadface",
    r":3+": "threeface",
    r":v+": "vface",
    r"\^\^": "kindsmile",
    r"\^_\^": "kindmountsmile",
    r"\^\.\^": "kindmountsmile",
    r"-_-": "disapointface",
    r"\._\.": "confusedface",
    r":>+": "cutesmile",
    r"(\|)w(\|)": "fancycryface",
    r":\|": "mutedface",
    r":d+": "laughface",
    r"<3": "loveicon",
    r"\.{2,}": "threedot",
    r"-{1,}>{1,}": "arrow",
    r"={1,}>{1,}": "arrow",
    r"(\d+)h": r"\1 gi·ªù",
    r"(\d+)'": r"\1 ph√∫t",
    r"(\d+)trieu": r"\1 tri·ªáu",
    r"(\d+)\s?tr": r"\1 tri·ªáu",
    r"blut\w+": "bluetooth",
}

MISPELLED_WORD_REPLACE = {
    "taay": "t√¢y",
    "gƒë": "gia ƒë√¨nh",
    "nch": "n√≥i chuy·ªán",
    "d·ªõi": "v·ªõi",
    "qu√©o": "qu√°",
    "thgian": "th·ªùi gian",
    "trc": "tr∆∞·ªõc",
    "gank": "g√°nh",
    "g√°nh tem": "g√°nh team",
    "cty": "c√¥ng ty",
    "film": "phim",
    "ch·∫øc": "ch·∫øt",
    "chec": "ch·∫øt",
    "hum": "h√¥m",
    "m·∫πt": "m·∫∑t",
    "bth": "b√¨nh th∆∞·ªùng",
    "bthg": "b√¨nh th∆∞·ªùng",
    "vde": "v·∫•n ƒë·ªÅ",
    "lg.bt": "lgbt",
    "eo gi bi ti": "lgbt",
    "·ªët ca": "oscar",
    "bik": "bi·∫øt",
    "thik": "th√≠ch",
    "ytb": "youtube",
    "fuk cu·ªëc": "ph·ª•c qu·ªëc",
    "vs": "v·ªõi",
    "cj": "ch·ªã",
    "chs": "ch∆°i",
    "trg": "trong",
    "gr": "group",
    "z·ªùi": "tr·ªùi",
    "tu·ªµt": "tuy·ªát",
    "tu·ªµt z·ªùi": "tuy·ªát v·ªùi",
    "jztr": "g√¨ v·∫≠y tr·ªùi",
    "dl": "deadline",
    "nhe": "nha",
    "c√†-ph√™": "c√† ph√™",
    "cafe": "c√† ph√™",
    "oach": "o√°ch",
    "ck": "ch·ªìng",
    "vk": "v·ª£",
    "c·ª©c": "c·ª©t",
    "m√∫n": "mu·ªën",
    "iu": "y√™u",
    "l≈©i": "l·ªói",
    "gei": "gay",
    "gkke": "gh√™",
    "ghia": "gh√™",
    "mn": "m·ªçi ng∆∞·ªùi",
    "mng": "m·ªçi ng∆∞·ªùi",
    "nh√¨u": "nhi·ªÅu",
    "nx": "n·ªØa",
    "cx": "c≈©ng",
    "del": "ƒë√©o",
    "ƒë·∫øu": "ƒë√©o",
    "dell": "ƒë√©o",
    "ƒë√©0": "ƒë√©o",
    "m·∫Ωo": "m·ªπ",
    "mƒ©": "m·ªπ",
    "ngoo": "ngu",
    "3///": "3 que",
    "ba ///": "3 que",
    "///": "3 que",
    "ba que": "3 que",
    "dlv": "d∆∞ lu·∫≠n vi√™n",
    "d·∫£k": "dark",
    "xaolol": "x·∫°o l·ªìn",
    "xao lol": "x·∫°o l·ªìn",
    "cg": "c≈©ng",
    "oce": "ok",
    "okla": "ok",
    "oke": "ok",
    "okay": "ok",
    "oki": "ok",
    "lu √¢n": "lu√¢n",
    "lun": "lu√¥n",
    "luon": "lu√¥n",
    "lu√¥ng": "lu√¥n",
    "ya": "yeah",
    "yah": "yeah",
    "yeh": "yeah",
    "ye": "yeah",
    "c√£": "c·∫£",
    "thi·ªác": "th·∫≠t",
    "thi·ªát": "th·∫≠t",
    "nka": "nha",
    "h·∫ª": "h·∫£",
    "ik": "ƒëi",
    "mik": "m√¨nh",
    "j": "g√¨",
    "jz": "g√¨ v·∫≠y",
    "s√¥ b√≠t": "showbiz",
    "s√¢u b√≠t": "showbiz",
    "uh": "·ª´",
    "ovtk": "overthinking",
    "duocj": "ƒë∆∞·ª£c",
    "dc": "ƒë∆∞·ª£c",
    "ƒëc": "ƒë∆∞·ª£c",
    "ro√†i": "r·ªìi",
    "vid": "video",
    "z": "v·∫≠y",
    "z·∫≠y": "v·∫≠y",
    "z·ªã": "v·∫≠y",
    "zui": "vui",
    "z·∫ª": "v·∫ª",
    "z·ªãt t√¢n": "vi·ªát t√¢n",
    "dui d·∫ª": "vui v·∫ª",
    "tr√πi": "tr·ªùi",
    "r√πi": "r·ªìi",
    "dth": "d·ªÖ th∆∞∆°ng",
    "thw": "th∆∞∆°ng",
    "hem": "kh√¥ng",
    "hok": "kh√¥ng",
    "ko": "kh√¥ng",
    "k": "kh√¥ng",
    "hok": "kh√¥ng",
    "hk": "kh√¥ng",
    "t·ª©k": "t·ª©c",
    "t∆∞k": "t·ª©c",
    "ch·∫ø—Ç": "ch·∫øt",
    "ƒë√©0": "ƒë√©o",
    "buo–º": "b∆∞·ªõm",
    "l—Ñ–∏": "l·ªìn",
    "l√¨n": "l·ªìn",
    "I·ªìn": "l·ªìn",
    "facebooj": "facebook",
    "fb": "facebook",
    "ins": "instagram",
    "i ponr": "iphone",
    "thi.√™.t <url>": "thi·ªát m·∫°ng",
    "c·ª´": "c∆∞·ªùi",
    "b·ªãnh": "b·ªánh",
    "ƒëin": "ƒëi√™n",
    "n–Ω√¢n": "nh√¢n",
    "k·ªôn": "l·ªôn",
    "s·∫£u": "s·ªßa",
    "ƒë'": "ƒë√©o",
    "m√®o ƒë·∫π": "ƒë√©o m·∫π",
    "ƒëhs": "ƒë√©o hi·ªÉu sao",
    "r√¢n ch·ªß": "d√¢n ch·ªß",
    "be ch√≠m": "chim b√©",
    "s·ªù trim m∆°": "streamer",
    "trim": "chim",
    "l√≤n": "l·ªìn",
    "ƒë≈©y": "ƒëƒ©",
    "ƒëix": "ƒëƒ©",
    "ƒë≈©y": "ƒëƒ©",
    "ear": "·ªâa",
    "·∫ª": "·ªâa",
    "·ªâe": "·ªâa",
    "üÜë": "c√°i l·ªìn",
    "cht": "ch·∫øt",
    "ng∆∞·ªùi r∆∞ng": "ng∆∞·ªùi d∆∞ng",
    "anh aays ddax bij ddwa ddeesn laau ddaif tinhf ais cura morderkaiser": "anh ·∫•y ƒë√£ b·ªã ƒë∆∞a ƒë·∫øn l√¢u ƒë√†i t√¨nh √°i c·ªßa mordekaiser",
    "anh se dua\nanh se dua em di toi brazil üó£Ô∏èüó£Ô∏èüáßüá∑": "anh s·∫Ω ƒë∆∞a\nanh s·∫Ω ƒë∆∞a em ƒëi t·ªõi brazil üó£Ô∏èüó£Ô∏èüáßüá∑",
    "slip": "sleep",
    "x·ª£": "s·ª£",
    "nu m∆∞·ªõc": "mu n∆∞·ªõc",
    "m√≤e": "m√®o",
    "cl": "c√°i l·ªìn",
    "tiktik": "tiktok",
    "tht": "th·∫≠t",
    "adu": "√° ƒë√π",
    "ukraine la con benh thi o vn co mot thang tuong benh hoan. ngao da vo hoc . ong bao thang he 43 tuoi lam tt con ong bn tuoi ma ong len lam he cho chung chuoi!": "ukraine l√† con b·ªánh th√¨ ·ªü vi·ªát nam th·∫±ng t∆∞·ªõng b·ªánh ho·∫°n. ng√°o ƒë√° v√¥ h·ªçc . √¥ng b·∫£o th·∫±ng h·ªÅ 43 tu·ªïi l√†m t·ªïng th·ªëng c√≤n √¥ng bao nhi√™u tu·ªïi m√† √¥ng l√™n l√†m h·ªÅ cho ch√∫ng ch·ª≠i",
    "vn": "vi·ªát nam",
    "tq": "trung qu·ªëc",
    "ch∆∞·ªüi": "ch·ª≠i",
    "admu": "admin",
    "ad": "admin",
    "adm": "admin",
    "·∫øu": "√©o",
    "p√†": "b√†",
    "ƒë·ª±t": "ƒë∆∞·ª£c",
    "khum": "kh√¥ng",
    "hong": "kh√¥ng",
    "ms": "m·ªõi",
    "bh": "b√¢y gi·ªù",
    "qias": "qu·∫£",
    "z√¥": "v√¥",
    "d√¥": "v√¥",
    "cmt": "comment",
    "cc": "con c·∫∑c",
    "dm": "ƒë·ªãt m·∫π",
    "ƒëm": "ƒë·ªãt m·∫π",
    "vc": "v√£i c·∫∑c",
    "vcd": "v√£i c·∫£ ƒë√°i",
    "vcƒë": "v√£i c·∫£ ƒë√°i",
    "cak": "c·∫∑c",
    "c·∫∑k": "c·∫∑c",
    "ƒëcm": "ƒë·ªãt con m·∫π",
    "ƒëkm": "ƒë·ªãt con m·∫π",
    "dcm": "ƒë·ªãt con m·∫π",
    "dkm": "ƒë·ªãt con m·∫π",
    "vcl": "v√£i c·∫£ l·ªìn",
    "vkl": "v√£i c·∫£ l·ªìn",
    "vl": "v√£i l·ªìn",
    "vler": "v√£i l·ªìn",
    "cmn": "con m·∫π n√≥",
    "cmnr": "con m·∫π n√≥ r·ªìi",
    "cmm": "con m·∫π m√†y",
    "clm": "con l·ªìn m·∫π",
    "trdu": "tr·ªùi ƒë·ª•",
    "l√πm m√≠a": "l·ªìn m√°",
    "ƒëjt": "ƒë·ªãt",
    "djt": "ƒë·ªãt",
    "kac": "c·∫∑c",
    "lz": "l·ªìn",
    "loz": "l·ªìn",
    "lol": "l·ªìn",
    "l·ªìl": "l·ªìn",
    "lul": "l·ªìn",
    "lz": "l·ªìn",
    "lone": "l·ªìn",
    "vlz": "v√£i l·ªìn",
    "c≈©m": "c≈©ng",
    "m·ªãa": "m·∫π",
    "m·ªçe": "m·∫π",
    "nghe muon ia": "nghe mu·ªën ·ªâa",
    "l i k e": "like",
    "tag": "tag",
    "xoq": "xong",
    "xog": "xong",
    "tri·∫øn s·ªπ": "chi·∫øn sƒ©",
    "tri·∫øk s·ªπ": "chi·∫øn sƒ©",
    "ukraina": "ukraine",
    "u c√†": "ukraine",
    "m·∫Ø": "m√°",
    "m√≥a": "m√°",
    "m√©": "m√°",
    "douma": "ƒë·ª• m√°",
    "duma": "ƒë·ª• m√°",
    "q√°": "qu√°",
    "oi": "∆°i",
    "√™i": "∆°i",
    "rp": "report",
    "r√¨ p·ªçt": "report",
    "kh": "kh√¥ng",
    "ƒë√°¬°i": "ƒë√°i",
    "nc": "n∆∞·ªõc",
    "gi√∫ng": "gi·ªëng",
    "ngta": "ng∆∞·ªùi ta",
    "chi·ªán": "chuy·ªán",
    "√∫n": "u·ªëng",
    "um x√πm": "um s√πm",
    "ae": "anh em",
    "md": "m·∫•t d·∫°y",
    "h·ª≠m": "h·∫£",
    "r√≤i": "r·ªìi",
    "g√≤i": "r·ªìi",
    "g·ªìi": "r·ªìi",
    "xoq": "xong",
    "xg": "xong",
    "xog": "xong",
    "gocu": "goku",
    "s∆°n gocu": "son goku",
    "cgi": "c√°i g√¨",
    "t.√¢.m t.h.·∫ß.n": "t√¢m th·∫ßn",
    "gs.": "gi√°o s∆∞",
    "ts.": "ti·∫øn sƒ©",
    "iem": "em",
    "h·ªâu": "hi·ªÉu",
    "ƒëb": "ƒë·∫ßu bu·ªìi",
    "ngiu": "ng∆∞·ªùi y√™u",
    "ny": "ng∆∞·ªùi y√™u",
    "ch√¨ ch√≠t": "ch√≠ chi·∫øt",
    "ch√≠t": "ch·∫øt",
    "hix": "hic",
    "ƒëth": "ƒëi·ªán tho·∫°i",
    "·ª•a": "·ªßa",
    "riu": "real",
    "riel": "real",
    "gv": "gi√°o vi√™n",
    "katyusha": "kachiusa",
    "vjp": "vip",
    "bruh": "bro",
    "uoc": "∆∞·ªõc",
    "kiu": "k√™u",
    "h·ªï tr·ª£": "h·ªó tr·ª£",
    "cdm": "c·ªông ƒë·ªìng m·∫°ng",
    "cƒëm": "c·ªông ƒë·ªìng m·∫°ng",
    "tbg": "tr∆∞ b√°t gi·ªõi",
    "p·∫øt": "page",
    "√≥": "√°",
    "ch√∫nh": "ch√∫ng",
    "thoai": "th√¥i",
    "vch": "v√£i ch∆∞·ªüng",
    "qtam": "quan t√¢m",
    "c·ª•a": "c·ªßa",
    "m·ªçincon": "m·ªçi con",
    "x√¨ tr√¢u": "x√¨ tr√¢y",
    "trung binh xi tray o moi truong tu nhien cua chung": "trung b√¨nh x√¨ tr√¢y ·ªü m√¥i tr∆∞·ªùng t·ª± nhi√™n c·ªßa ch√∫ng",
    "ma t√≥e": "ma t√∫y",
    "‚Ñ¨ùí∂ÃÜÃÅùí∏ ùìÄùìéÃÄ": "b·∫Øc k·ª≥",
    "c√°i=": "c√°i b·∫±ng",
    "n·ªën l·ª´ng": "n·ª©ng l·ªìn",
    "gi·∫ø—Ç": "gi·∫øt",
}

uniChars = "√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥√ÇƒÇƒê√î∆†∆Ø"
unsignChars = "aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU"


def loaddicchar():
    dic = {}
    char1252 = "√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥".split(
        "|"
    )
    charutf8 = "√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥".split(
        "|"
    )
    for i in range(len(char1252)):
        dic[char1252[i]] = charutf8[i]
    return dic


dicchar = loaddicchar()


def convert_unicode(txt):
    return re.sub(
        r"√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥",
        lambda x: dicchar[x.group()],
        txt,
    )


vowel_table = [
    ["a", "√†", "√°", "·∫£", "√£", "·∫°", "a"],
    ["ƒÉ", "·∫±", "·∫Ø", "·∫≥", "·∫µ", "·∫∑", "aw"],
    ["√¢", "·∫ß", "·∫•", "·∫©", "·∫´", "·∫≠", "aa"],
    ["e", "√®", "√©", "·∫ª", "·∫Ω", "·∫π", "e"],
    ["√™", "·ªÅ", "·∫ø", "·ªÉ", "·ªÖ", "·ªá", "ee"],
    ["i", "√¨", "√≠", "·ªâ", "ƒ©", "·ªã", "i"],
    ["o", "√≤", "√≥", "·ªè", "√µ", "·ªç", "o"],
    ["√¥", "·ªì", "·ªë", "·ªï", "·ªó", "·ªô", "oo"],
    ["∆°", "·ªù", "·ªõ", "·ªü", "·ª°", "·ª£", "ow"],
    ["u", "√π", "√∫", "·ªß", "≈©", "·ª•", "u"],
    ["∆∞", "·ª´", "·ª©", "·ª≠", "·ªØ", "·ª±", "uw"],
    ["y", "·ª≥", "√Ω", "·ª∑", "·ªπ", "·ªµ", "y"],
]
keyboard_accents_table = ["", "f", "s", "r", "x", "j"]

nguyen_am_to_ids = {}

for i in range(len(vowel_table)):
    for j in range(len(vowel_table[i]) - 1):
        nguyen_am_to_ids[vowel_table[i][j]] = (i, j)


def chuan_hoa_dau_tu_tieng_viet(word):
    if not is_valid_vietnam_word(word):
        return word

    chars = list(word)
    dau_cau = 0
    nguyen_am_index = []
    qu_or_gi = False
    for index, char in enumerate(chars):
        x, y = nguyen_am_to_ids.get(char, (-1, -1))
        if x == -1:
            continue
        elif x == 9:  # check qu
            if index != 0 and chars[index - 1] == "q":
                chars[index] = "u"
                qu_or_gi = True
        elif x == 5:  # check gi
            if index != 0 and chars[index - 1] == "g":
                chars[index] = "i"
                qu_or_gi = True
        if y != 0:
            dau_cau = y
            chars[index] = vowel_table[x][0]
        if not qu_or_gi or index != 1:
            nguyen_am_index.append(index)
    if len(nguyen_am_index) < 2:
        if qu_or_gi:
            if len(chars) == 2:
                x, y = nguyen_am_to_ids.get(chars[1])
                chars[1] = vowel_table[x][dau_cau]
            else:
                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))
                if x != -1:
                    chars[2] = vowel_table[x][dau_cau]
                else:
                    chars[1] = (
                        vowel_table[5][dau_cau]
                        if chars[1] == "i"
                        else vowel_table[9][dau_cau]
                    )
            return "".join(chars)
        return word

    for index in nguyen_am_index:
        x, y = nguyen_am_to_ids[chars[index]]
        if x == 4 or x == 8:  # √™, ∆°
            chars[index] = vowel_table[x][dau_cau]
            # for index2 in nguyen_am_index:
            #     if index2 != index:
            #         x, y = nguyen_am_to_ids[chars[index]]
            #         chars[index2] = bang_nguyen_am[x][0]
            return "".join(chars)

    if len(nguyen_am_index) == 2:
        if nguyen_am_index[-1] == len(chars) - 1:
            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]
            chars[nguyen_am_index[0]] = vowel_table[x][dau_cau]
            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]
            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]
        else:
            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]
            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]
            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]
            chars[nguyen_am_index[1]] = vowel_table[x][dau_cau]
    else:
        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]
        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]
        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]
        chars[nguyen_am_index[1]] = vowel_table[x][dau_cau]
        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]
        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]
    return "".join(chars)


def is_valid_vietnam_word(word):
    chars = list(word)
    nguyen_am_index = -1
    for index, char in enumerate(chars):
        x, y = nguyen_am_to_ids.get(char, (-1, -1))
        if x != -1:
            if nguyen_am_index == -1:
                nguyen_am_index = index
            else:
                if index - nguyen_am_index != 1:
                    return False
                nguyen_am_index = index
    return True


def normalize_vietnamese_accents(sentence):
    """
    Chuy·ªÉn c√¢u ti·∫øng vi·ªát v·ªÅ chu·∫©n g√µ d·∫•u ki·ªÉu c≈©.
    :param sentence:
    :return:
    """
    words = sentence.split()
    for index, word in enumerate(words):
        cw = re.sub(r"(^\p{P}*)([p{L}.]*\p{L}+)(\p{P}*$)", r"\1/\2/\3", word).split("/")
        # print(cw)
        if len(cw) == 3:
            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])
        words[index] = "".join(cw)
    return " ".join(words)


def normalize(text: str, track_change=False):
    # Lowercasing
    text = text.lower()

    # NFKC
    text = unicodedata.normalize("NFKC", text)
    if track_change:
        print("NFKC: ", text)

    # Remove dup trailing chars (troiiiii -> troi)
    text = DUP_TRALLING_RE.sub(r"\1", text)
    if track_change:
        print("Dedup trailing: ", text)

    # Replace special symbol to word
    for pttn, repl in SPECIAL_WORD_SUBSTITUTION.items():
        text = re.sub(rf"{pttn}", f" {repl} ", text)
    if track_change:
        print("Replace special word: ", text)

    # text = text.replace("<username>", "@username")
    # Correct misspelled word
    # def replace(match):
    #     orig = match.group(0)
    #     word = " " + MISPELLED_WORD_REPLACE.get(orig, orig) + " "
    #     return word

    # text = SYLLABLE_RE.sub(replace, text)
    # if track_change:
    #     print("Correct misspelled word: ", text)

    # Normalize string encoding
    text = convert_unicode(text)
    if track_change:
        print("Normalize string encoding: ", text)

    # Vietnamese diacritic normalization
    text = normalize_vietnamese_accents(text)
    if track_change:
        print("Vietnamese unicode normalization: ", text)

    # Eliminate grouping separator (9.000 / 9,000 -> 9000)
    text = GROUPING_SEPARATOR_RE.sub("", text)
    if track_change:
        print("Eliminate decimal delimiter: ", text)

    # Split between value and unit (300km -> 300 km)
    text = VALUE_UNIT_RE.sub(r"\1 \2", text)
    if track_change:
        print("Split between value and unit: ", text)

    # Split by punctuations
    text = " ".join(filter(None, PUNCTUATION_RE.split(text)))
    if track_change:
        print("Split by punctuations: ", text)

    # Split by emojis
    # text = " ".join(EMOJI_RE.split(text))
    text = emoji.replace_emoji(text, lambda e, d: f" {e} ")
    if track_change:
        print("Split by emojis: ", text)

    # Word segmentation
    # text = " ".join(vncorenlp.word_segment(text))

    return text